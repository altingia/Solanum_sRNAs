"""
Snakefile
"""
#############################
# Load pipeline configuration
#############################
configfile: "config.yaml"

WORKING_DIR = config["workdir"]
RESULT_DIR = config["resultdir"]
THREADS = config["threads"]


# Get wildcards
SAMPLES, = glob_wildcards(config["fastqdir"] + "{sample}.fastq.gz")

#################
# Desired output
#################
BAMS = expand(RESULT_DIR + "{sample}_Aligned.sortedByCoord.out.bam",sample=SAMPLES)
BIGWIGS = expand(RESULT_DIR + "{sample}_Signal.{u}.bw",sample=SAMPLES,u=["Unique","UniqueMultiple"])

rule all:
	input:
		BAMS,
		BIGWIGS
	message:"all done!"
   
#################
# Snakemake rules
#################


###################
# Convert to bigwig
###################
rule bedgraph2bigwig:
    input:
        bg = RESULT_DIR + "{sample}_Signal.{u}.out.wig",
        chrom = config["refs"]["chromsizes"]
    output:
        RESULT_DIR + "{sample}_Signal.{u}.bw",
    message:"converting {input.bg} file to bigwig"
    shell:
        "wigToBigWig {input.bg} {input.chrom} {output}"
             
##########################
# STAR map reads to genome
##########################
rule map_to_genome_using_STAR:
    input:
        ref = [WORKING_DIR + "star2pass/"+f for f in ["chrLength.txt","chrNameLength.txt","chrName.txt","chrStart.txt","Genome","genomeParameters.txt","SA","SAindex"]],
        reads = WORKING_DIR + "trimmed/{sample}.fastq.gz"
    output:
        RESULT_DIR + "{sample}_Aligned.sortedByCoord.out.bam",
        RESULT_DIR + "{sample}_Aligned.sortedByCoord.out.bam.bai",
        RESULT_DIR + "{sample}_Log.final.out",
	RESULT_DIR + "{sample}_Signal.Unique.out.wig",
        RESULT_DIR + "{sample}_Signal.UniqueMultiple.out.wig",   
    message:"mapping the {wildcards.sample} reads to genome"
    params:
        prefix = RESULT_DIR + "{sample}_",
        maxmismatches = config["star"]["mismatches"],
        unmapped = config["star"]["unmapped"]	,
        multimappers = config["star"]["multimappers"],
        matchNminoverLread = config["star"]["matchminoverlengthread"],
	outSamType = config["star"]["samtype"],
        outWigType = config["star"]["outwigtype"],
        outWigStrand = config["star"]["outwigstrand"],
        outWigNorm = config["star"]["outwignorm"],
        intronmax = config["star"]["intronmax"],
        matesgap =  config["star"]["matesgap"],
        genomeLoad = config["star"]["genomeload"],
        genomeram = config["star"]["genomeram"],
        genomedir = WORKING_DIR + "star2pass/"
    shell:
            "STAR --genomeDir {params.genomedir} "
            "--readFilesIn {input.reads} "
            "--readFilesCommand zcat "
            "--outFilterMultimapNmax {params.multimappers} "
            "--outFilterMismatchNmax {params.maxmismatches} "
            "--alignMatesGapMax {params.matesgap} "
            "--alignIntronMax {params.intronmax} "
            "--outFilterMatchNminOverLread {params.matchNminoverLread} "
            "--alignEndsType EndToEnd "
            "--runThreadN {THREADS} "
            "--outReadsUnmapped {params.unmapped} "
            "--outFileNamePrefix {params.prefix} "
            "--outSAMtype {params.outSamType} "
            "--outWigType {params.outWigType} "
            "--outWigStrand {params.outWigStrand} "
            "--outWigNorm {params.outWigNorm} "
            "--genomeLoad {params.genomeLoad} "
            "--limitGenomeGenerateRAM {params.genomeram};"
            "samtools index {output[0]}"

#####################################################################
## STAR 2-pass: genome indexing + splice junctions database generation 
#####################################################################
rule star2pass_index:
    input:
        sjdb = WORKING_DIR + "star1pass/SJ.concatenated.out.tab", 
        ref= config["refs"]["genome"],
        gtf = config["refs"]["gtf"]
    output:
        STAR_2PASS = [WORKING_DIR + "star2pass/"+ f for f in ["chrLength.txt","chrNameLength.txt","chrName.txt","chrStart.txt","Genome","genomeParameters.txt","SA","SAindex"]]
    message: "STAR 2nd pass: generating genome index"	
    params:
        WORKING_DIR + "star2pass/"
    shell:
        "STAR --runMode genomeGenerate "
        "--genomeDir {params} "
        "--genomeFastaFiles {input.ref} "
        "--runThreadN {THREADS} "
        "--sjdbFileChrStartEnd {input.sjdb} "
        "--sjdbOverhang 99 "
        "--sjdbGTFfile {input.gtf};"
        "touch -h {output}"

rule concatenate_sjdb:
    input:
        expand(WORKING_DIR + "star1pass/{sample}_SJ.out.tab",sample=SAMPLES),
    output:
        WORKING_DIR + "star1pass/SJ.concatenated.out.tab"
    message:"concatenating splice junctions from different samples "
    shell:"cat {input} >> {output}"

rule star1pass_align:
    input:
        reads = WORKING_DIR + "trimmed/{sample}.fastq.gz",
        ref = WORKING_DIR + "star_index/"
    output:
        WORKING_DIR + "star1pass/{sample}_SJ.out.tab",
        temp(WORKING_DIR + "star1pass/{sample}_Aligned.out.sam")
    message:"STAR 1st pass: aligning {wildcards.sample} reads to generate splice junction files"
    params:
        WORKING_DIR + "star1pass/{sample}_"	
    shell: 		
        "STAR --runMode alignReads "
        "--genomeDir {input.ref} "
        "--readFilesIn {input.reads} "
        "--outFileNamePrefix {params} "
        "--outFilterIntronMotifs RemoveNoncanonical "
        "--runThreadN {THREADS} "
        "--readFilesCommand zcat"

# sdjbOverhang specifies the length of the genomic sequence around the annotated junction to be used in constructing the splie junctions database. 
#Ideally this length should be equal to ReadLength-1
rule star_index:
    input:
        genome = config["refs"]["genome"],
        gtf = config["refs"]["gtf"]
    output:
        WORKING_DIR + "star_index/"
    message:"generation STAR genome index" 
    params:
        WORKING_DIR + "star_index/"
    shell:
        "mkdir -p {params};"
        "STAR --runMode genomeGenerate "
        "--genomeDir {params} "
        "--genomeFastaFiles {input.genome} "
        "--runThreadN {THREADS} "
        "--sjdbOverhang 99 "
        "--sjdbGTFfile {input.gtf}"

######### 
#trimming
#########
rule fastx_quality:
    input:
        fastq = config["fastqdir"] + "{sample}.fastq.gz"
    output:
        WORKING_DIR + "trimmed/{sample}.fastq.gz"
    message: "removing low quality bases from {wildcards.sample} reads"
    log:
        RESULT_DIR + "logs/fastx/{sample}.log"
    params :
        qual = str(config['trimmomatic']['seedMisMatches']),
    shell:
        "fastq_quality_filter "
        "-v " 				# verbose
        "-q {params.qual} " 		# Minimum quality score to keep 
        "-z "				# compress output with gzip
        "-i {input} -o {output} "		 





